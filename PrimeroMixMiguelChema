/* Master en Ingeniería Informática - Universidad de Valladolid
*
*  TECNICAS ESCLABLES DE ANÁLISIS DE DATOS EN ENTORNOS BIG DATA: Regresión y descubrimiento de conocimiento
*  Mini-Proyecto 1 : Recomendadores
*
*  Dataset: CDs and Vinyl
* 
*  Primer script
*
*  Grupo 2: Sergio Agudelo Bernal
*           Miguel Ángel Collado Alonso
*           José María Lozano Olmedo.
*/


// iniciar sesión como $> spark-shell --driver-memory 4g

import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.recommendation.{ALS, ALSModel}
import org.apache.spark.ml.tuning.{CrossValidator,CrossValidatorModel}
import org.apache.spark.ml.evaluation.RegressionEvaluator
import org.apache.spark.ml.tuning.ParamGridBuilder
import java.util.Calendar
import java.sql.Timestamp
import java.text.SimpleDateFormat


val PATH="/home/usuario/Regresion/MiniProyecto1/"
val ARCHIVO="CDs_and_Vinyl.csv"

// formato del archivo de datos: item,user,rating,timestamp separados por ,

case class Rating(item: String, itemId: Int, user: String, userId: Int, rating: Float, timestamp: Long)
def parseRating(str: String): Rating = {
  val fields = str.split(",")
  assert(fields.size == 4)
  Rating(fields(0), fields(0).hashCode, fields(1), fields(1).hashCode, fields(2).toFloat, fields(3).toLong)
}

val ratings = spark.read.textFile(PATH + ARCHIVO).map(parseRating).toDF()

// Eliminamos nulos
  
val dfCDsVinyl = ratings.na.drop()

// Exploración de los datos
   
println("Número total de registros: " + dfCDsVinyl.count())
println("Primeros 5 registros:")
dfCDsVinyl.show(5)
println("Estructura del DataFrame:")
dfCDsVinyl.printSchema()

println("Resumen estadístico de Rating:")
dfCDsVinyl.describe("rating").show()

println("Número de votos por valor:")
dfCDsVinyl.groupBy("rating").count().orderBy(desc("count")).withColumnRenamed("count", "cuenta").show()

val MinMaxTime = dfCDsVinyl.agg(min("timestamp"),max("timestamp")).head()

// Convertir el timestamp a formato de fecha
val dateFormat = new SimpleDateFormat("dd-MM-yyyy hh:mm")
val minFecha = new Timestamp(MinMaxTime.getLong(0) * 1000L) // Multiplicamos por 1000L porque Timestamp espera milisegundos
val maxFecha = new Timestamp(MinMaxTime.getLong(1) * 1000L) // Multiplicamos por 1000L porque Timestamp espera milisegundos
val minFechaStr = dateFormat.format(minFecha)
val maxFechaStr = dateFormat.format(maxFecha)

println("Mínimo valor de timestamp:" + MinMaxTime(0) + " -> " +  minFechaStr)
println("Máximo valor de timestamp:" + MinMaxTime(1) + " -> " +  maxFechaStr)

println("Número de productos (Item): " + dfCDsVinyl.select("item").distinct.count())
println("Número de usuarios (User): " + dfCDsVinyl.select("user").distinct.count())


// Particionado del Dataset

// **** particionado para hacer las pruebas ****
val Array(training, test) = dfCDsVinyl.randomSplit(Array(0.005, 0.005))

// **** particionado real ****
// val Array(training, test) = dfCDsVinyl.randomSplit(Array(0.8, 0.2))


test.write.csv("/home/usuario/Regresion/MiniProyecto1/conjunto-test")
println("Conjunto de test guardado")


val als = new ALS().setUserCol("userId").setItemCol("itemId").setRatingCol("rating")

val paramGrid = new ParamGridBuilder().addGrid(als.rank, Array(2,3,5)).addGrid(als.regParam, Array(0.01, 0.1,0.2)).addGrid(als.maxIter, Array(5,7,10)).build()

val evaluator = new RegressionEvaluator()
evaluator.setMetricName("rmse")
evaluator.setLabelCol("rating")
evaluator.setPredictionCol("prediction")


val cv1 = new CrossValidator().setEstimator(als).setEstimatorParamMaps(paramGrid).setEvaluator(evaluator).setNumFolds(2)

println(s"Inicio: ${Calendar.getInstance.getTime}")


val cvmodel1 = cv1.fit(training)

println(s"Fin: ${Calendar.getInstance.getTime}")

val model = cvmodel1.bestModel.asInstanceOf[ALSModel]

//model.getRank
println(model)
model.write.overwrite().save("/home/usuario/Regresion/MiniProyecto1/modeloALS")


model.setColdStartStrategy("drop")
val predictions = model.transform(test)

val rmse = evaluator.evaluate(predictions)
println(s"Root-mean-square error = $rmse")

