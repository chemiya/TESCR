/* Master en Ingeniería Informática - Universidad de Valladolid
*
*  TECNICAS ESCLABLES DE ANÁLISIS DE DATOS EN ENTORNOS BIG DATA: Regresión y descubrimiento de conocimiento
*  Mini-Proyecto 1 : Recomendadores
*
*  Dataset: CDs and Vinyl
* 
*  Primer script
*
*  Grupo 2: Sergio Agudelo Bernal
*           Miguel Ángel Collado Alonso
*           José María Lozano Olmedo.
*/


// iniciar sesión como $> spark-shell --driver-memory 4g


import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.recommendation.{ALS, ALSModel}
import org.apache.spark.ml.tuning.{CrossValidator,CrossValidatorModel}
import org.apache.spark.ml.evaluation.RegressionEvaluator
import org.apache.spark.ml.tuning.ParamGridBuilder
import java.util.Calendar


val PATH="/home/usuario/Regresion/MiniProyecto1/"
val ARCHIVO="CDs_and_Vinyl.csv"

// formato del archivo de datos: item,user,rating,timestamp separados por ,

case class Rating(item: String, itemId: Int, user: String, userId: Int, rating: Float, timestamp: Long)
def parseRating(str: String): Rating = {
  val fields = str.split(",")
  assert(fields.size == 4)
  Rating(fields(0), fields(0).hashCode, fields(1), fields(1).hashCode, fields(2).toFloat, fields(3).toLong)
}

val ratings = spark.read.textFile(PATH + ARCHIVO).map(parseRating).toDF()

// Eliminamos nulos
  
val dfCDsVinyl = ratings.na.drop()


// Explorar los datos
   
println("Número total de filas: " + dfCDsVinyl.count())
println("Primeras 5 filas:")
dfCDsVinyl.show(5)
println("Estructura del DataFrame:")
dfCDsVinyl.printSchema()

  
 // Realizar análisis exploratorio de los ratings
    
println("Resumen estadístico de la columna 'rating':")
dfCDsVinyl.describe("rating").show()

// **** particionado para hacer las pruebas ****
val Array(training, test) = dfCDsVinyl.randomSplit(Array(0.1, 0.05))

// **** particionado real ****
// val Array(training, test) = dfCDsVinyl.randomSplit(Array(0.8, 0.2))


test.write.csv("/home/usuario/Regresion/MiniProyecto1/conjunto-test")
println("Conjunto de test guardado")


val als = new ALS().setUserCol("userId").setItemCol("itemId").setRatingCol("rating")

val paramGrid = new ParamGridBuilder().addGrid(als.rank, Array(2,3,5)).addGrid(als.regParam, Array(0.01, 0.1,0.2)).addGrid(als.maxIter, Array(5,7,10)).build()

val evaluator = new RegressionEvaluator()
evaluator.setMetricName("rmse")
evaluator.setLabelCol("rating")
evaluator.setPredictionCol("prediction")


val cv1 = new CrossValidator().setEstimator(als).setEstimatorParamMaps(paramGrid).setEvaluator(evaluator).setNumFolds(2)

println(s"Inicio: ${Calendar.getInstance.getTime}")


val cvmodel1 = cv1.fit(training)

println(s"Fin: ${Calendar.getInstance.getTime}")

val model = cvmodel1.bestModel.asInstanceOf[ALSModel]

//model.getRank
println(model)
model.write.overwrite().save("/home/usuario/Regresion/MiniProyecto1/modelo")


model.setColdStartStrategy("drop")
val predictions = model.transform(test)

val rmse = evaluator.evaluate(predictions)
println(s"Root-mean-square error = $rmse")
